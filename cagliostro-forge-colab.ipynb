{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a79c0336b29048f6b476ad58f7773b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1103b54b213243b88bca64da8b30e39e",
              "IPY_MODEL_edc924b9efcc4414a07612c80d363c0b"
            ],
            "layout": "IPY_MODEL_3d7b06afdc9e45e6af37a55a80c96e80"
          }
        },
        "1103b54b213243b88bca64da8b30e39e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29536413c02e4691b1009c82b5bc38b2",
              "IPY_MODEL_d61ce80ae4ae499aa441514b87b9390c",
              "IPY_MODEL_c18a96b487ee49a7924f6b85ffa86082",
              "IPY_MODEL_c1f9fdde098549e9bf33e4af1ccbc816"
            ],
            "layout": "IPY_MODEL_052d6623a20e42e1b33faced0424ebe5"
          }
        },
        "edc924b9efcc4414a07612c80d363c0b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f4fee83908f4446eb177cedfa7cec51b",
            "msg_id": "",
            "outputs": []
          }
        },
        "3d7b06afdc9e45e6af37a55a80c96e80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29536413c02e4691b1009c82b5bc38b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "URL:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ea2b2e6925d14d19bcafd4e3fdddbf3c",
            "placeholder": "​",
            "style": "IPY_MODEL_86204a62687b4849bbd1d3e60ea2d7a0",
            "value": ""
          }
        },
        "d61ce80ae4ae499aa441514b87b9390c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Name:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b729ff5371524e4c9d57531457a6e33c",
            "placeholder": "​",
            "style": "IPY_MODEL_d86e07de31b649a0b81a9da3ec7da10e",
            "value": ""
          }
        },
        "c18a96b487ee49a7924f6b85ffa86082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "checkpoint",
              "vae",
              "lora"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Destination:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_c5b9d666668e4c48971084cc29509d01",
            "style": "IPY_MODEL_aa64f80531bb4d3396b8b06d759432b3"
          }
        },
        "c1f9fdde098549e9bf33e4af1ccbc816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Add Item",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_2264c7ea9139490eb3f5a12f8fa312a7",
            "style": "IPY_MODEL_a878043ea4164b469368d22d57533ec4",
            "tooltip": ""
          }
        },
        "052d6623a20e42e1b33faced0424ebe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea2b2e6925d14d19bcafd4e3fdddbf3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86204a62687b4849bbd1d3e60ea2d7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b729ff5371524e4c9d57531457a6e33c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d86e07de31b649a0b81a9da3ec7da10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5b9d666668e4c48971084cc29509d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa64f80531bb4d3396b8b06d759432b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2264c7ea9139490eb3f5a12f8fa312a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a878043ea4164b469368d22d57533ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f4fee83908f4446eb177cedfa7cec51b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![visitor][visitor-badge]][visitor-stats]\n",
        "\n",
        "# **Cagliostro Forge Colab**\n",
        "Rise from the ashes, reborn and empowered by [lllyasviel/stable-diffusion-webui-forge](https://github.com/lllyasviel/stable-diffusion-webui-forge)\n",
        "\n",
        "**Version 1.0.0** | [Github][link-to-github] | [License](https://github.com/cagliostrolab/forge-colab/blob/main/LICENSE)\n",
        "\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=cagliostro-forge-colab&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=cagliostro-forge-colab\n",
        "[link-to-github]: https://github.com/cagliostrolab/forge-colab/blob/main/cagliostro-forge-colab.ipynb"
      ],
      "metadata": {
        "id": "GnmYPpV3o719"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from ipywidgets import widgets, HBox, VBox\n",
        "from IPython.display import display, clear_output\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# ROOT DIR\n",
        "root_dir        = Path(\"/content\")\n",
        "drive_dir       = root_dir / \"drive\" / \"MyDrive\"\n",
        "repo_dir        = root_dir / \"stable-diffusion-webui-forge\"\n",
        "tmp_dir         = root_dir / \"tmp\"\n",
        "models_dir      = repo_dir / \"models\"\n",
        "extensions_dir  = repo_dir / \"extensions\"\n",
        "ckpt_dir        = models_dir / \"Stable-diffusion\"\n",
        "vae_dir         = models_dir / \"VAE\"\n",
        "lora_dir        = models_dir / \"Lora\"\n",
        "\n",
        "class DownLoadItem(BaseModel):\n",
        "    url: str\n",
        "    name: str\n",
        "    destPath: str\n",
        "\n",
        "# Create a list of available destination paths\n",
        "available_dest_paths = [\n",
        "    'checkpoint',\n",
        "    'vae',\n",
        "    'lora',\n",
        "]\n",
        "\n",
        "true_dest_paths = {\n",
        "    'checkpoint' : str(ckpt_dir),\n",
        "    'vae' : str(vae_dir),\n",
        "    'lora' : str(lora_dir)\n",
        "}\n",
        "\n",
        "def on_add_button_clicked(b):\n",
        "    with output_area:\n",
        "        # Clear the previous output\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Get values from input widgets\n",
        "        item = DownLoadItem(\n",
        "            url = url_input.value,\n",
        "            name = name_input.value,\n",
        "            destPath = true_dest_paths[dest_path_input.value]\n",
        "        )\n",
        "\n",
        "        # Add the new item to the list\n",
        "        download_items.append(item)\n",
        "\n",
        "        # Print the current list to the output area\n",
        "        print(\"Current Download Queue:\")\n",
        "        for i, item in enumerate(download_items):\n",
        "            print(f\"  Item {i+1}: {item}\")\n",
        "\n",
        "        # Reset the text input fields\n",
        "        url_input.value = ''\n",
        "        name_input.value = ''\n",
        "\n",
        "        # Correctly reset the dropdown to its default value\n",
        "        # The value is set to the first option in the list\n",
        "        # dest_path_input.value = dest_path_input.options[0]  # error, comment out\n",
        "\n",
        "# Create input fields\n",
        "url_input = widgets.Text(description=\"URL:\")\n",
        "name_input = widgets.Text(description=\"Name:\")\n",
        "# Use Dropdown instead of Text for the destination path\n",
        "dest_path_input = widgets.Dropdown(\n",
        "    options=available_dest_paths,\n",
        "    value=available_dest_paths[0],  # Set a default value\n",
        "    description=\"Destination:\"\n",
        ")\n",
        "\n",
        "# Create a button to add items\n",
        "add_button = widgets.Button(description=\"Add Item\")\n",
        "\n",
        "# Create a display area for the list of items\n",
        "output_area = widgets.Output()\n",
        "\n",
        "# This list will store your data\n",
        "download_items = [DownLoadItem(url='https://civitai.com/api/download/models/290640?type=Model&format=SafeTensor&size=pruned&fp=fp16', name='ponyDiffusionV6XL_v6StartWithThisOne.safetensors', destPath=str(ckpt_dir)),\n",
        "                  DownLoadItem(url='https://civitai.com/api/download/models/412844?type=Model&format=SafeTensor', name='LeagueOfLegendsPony.safetensors', destPath=str(lora_dir)),\n",
        "                  DownLoadItem(url='https://civitai.com/api/download/models/290640?type=VAE&format=SafeTensor', name='sdxl_vae.safetensors', destPath=str(vae_dir)),\n",
        "\n",
        "                  ]\n",
        "\n",
        "# Link the button to the function\n",
        "add_button.on_click(on_add_button_clicked)\n",
        "\n",
        "# Arrange the widgets in a box layout\n",
        "input_widgets = VBox([url_input, name_input, dest_path_input, add_button])\n",
        "ui = VBox([input_widgets, output_area])\n",
        "\n",
        "# Display the UI\n",
        "display(ui)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "a79c0336b29048f6b476ad58f7773b7b",
            "1103b54b213243b88bca64da8b30e39e",
            "edc924b9efcc4414a07612c80d363c0b",
            "3d7b06afdc9e45e6af37a55a80c96e80",
            "29536413c02e4691b1009c82b5bc38b2",
            "d61ce80ae4ae499aa441514b87b9390c",
            "c18a96b487ee49a7924f6b85ffa86082",
            "c1f9fdde098549e9bf33e4af1ccbc816",
            "052d6623a20e42e1b33faced0424ebe5",
            "ea2b2e6925d14d19bcafd4e3fdddbf3c",
            "86204a62687b4849bbd1d3e60ea2d7a0",
            "b729ff5371524e4c9d57531457a6e33c",
            "d86e07de31b649a0b81a9da3ec7da10e",
            "c5b9d666668e4c48971084cc29509d01",
            "aa64f80531bb4d3396b8b06d759432b3",
            "2264c7ea9139490eb3f5a12f8fa312a7",
            "a878043ea4164b469368d22d57533ec4",
            "f4fee83908f4446eb177cedfa7cec51b"
          ]
        },
        "id": "2VtO1METfZh7",
        "outputId": "e6d555be-cf9c-4cbe-a758-514a6d35ac07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(VBox(children=(Text(value='', description='URL:'), Text(value='', description='Name:'), Dropdow…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a79c0336b29048f6b476ad58f7773b7b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Install Environment**\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import string\n",
        "import textwrap\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "python_version  = \".\".join(sys.version.split(\".\")[:2])\n",
        "python_path     = Path(f\"/usr/local/lib/python{python_version}/dist-packages/\")\n",
        "colablib_path   = python_path / \"colablib\"\n",
        "if not colablib_path.exists():\n",
        "    subprocess.run(['pip', 'install', '--upgrade', 'git+https://github.com/Linaqruf/colablib'], check=True)\n",
        "\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.utils import py_utils, package_utils, config_utils\n",
        "from colablib.sd_models.downloader import aria2_download, download\n",
        "from colablib.utils.git_utils import update_repo, reset_repo, validate_repo, batch_update\n",
        "from colablib.utils.py_utils import get_filename\n",
        "\n",
        "\n",
        "################################\n",
        "# COLAB ARGUMENTS GOES HERE\n",
        "################################\n",
        "\n",
        "# It ain't much, but it's honest work.\n",
        "class CustomDirs(BaseModel):\n",
        "    url: str\n",
        "    dst: str\n",
        "\n",
        "# @markdown ### **Drive Config**\n",
        "mount_drive          = False  # @param {type: 'boolean'}\n",
        "output_drive_folder  = \"cagliostro-colab-forge\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown ### **Repo Config**\n",
        "update_webui         = False  # @param {type: 'boolean'}\n",
        "update_extensions    = False  # @param {type: 'boolean'}\n",
        "commit_hash          = \"\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown ### **Download Config**\n",
        "# @markdown > Check only the options you need\n",
        "animagine_xl_3_1     = True  # @param {type: 'boolean'}\n",
        "rae_diffusion_xl_v2  = False  # @param {type: 'boolean'}\n",
        "kivotos_xl_v2_0      = False  # @param {type: 'boolean'}\n",
        "urangdiffusion_2_0   = False  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown > **Note:**\n",
        "# @markdown - For multiple URLs, use comma separation (e.g. `url1, url2, url3`)\n",
        "# @markdown - Forge supports FLUX, SD, and SDXL, but this notebook focuses only on SDXL\n",
        "# @markdown - **Highly Recommended:** Use Hugging Face links whenever possible\n",
        "custom_model_url     = \"\"  # @param {'type': 'string'}\n",
        "custom_vae_url       = \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl.vae.safetensors\"  # @param {'type': 'string'}\n",
        "custom_lora_url      = \"\"  # @param {'type': 'string'}\n",
        "\n",
        "\n",
        "\n",
        "# You can now use this list for your download logic\n",
        "# e.g., for item in download_items:\n",
        "#            your_download_function(item['url'], item['name'], item['destPath'])\n",
        "\n",
        "# @markdown ### **Tunnel Config**\n",
        "# @markdown > Default to `--share` until `ngrok_token` is not `None`\n",
        "ngrok_token          = \"31K1MAUQixUUOkkds39k2sszYxJ_mgMidZTnzeVHnDSa6Nma\"  # @param {type: 'string'}\n",
        "ngrok_region         = \"jp\"  # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "# @markdown ### **UI/UX Config**\n",
        "gradio_theme         = \"remilia/Ghostly\"  # @param [\"Default\", \"gradio/base\", \"gradio/glass\", \"gradio/monochrome\", \"gradio/seafoam\", \"gradio/soft\", \"gradio/dracula_test\", \"abidlabs/dracula_test\", \"abidlabs/Lime\", \"abidlabs/pakistan\", \"Ama434/neutral-barlow\", \"dawood/microsoft_windows\", \"finlaymacklon/smooth_slate\", \"Franklisi/darkmode\", \"freddyaboulton/dracula_revamped\", \"freddyaboulton/test-blue\", \"gstaff/xkcd\", \"Insuz/Mocha\", \"Insuz/SimpleIndigo\", \"JohnSmith9982/small_and_pretty\", \"nota-ai/theme\", \"nuttea/Softblue\", \"ParityError/Anime\", \"reilnuud/polite\", \"remilia/Ghostly\", \"rottenlittlecreature/Moon_Goblin\", \"step-3-profit/Midnight-Deep\", \"Taithrah/Minimal\", \"ysharma/huggingface\", \"ysharma/steampunk\", \"NoCrypt/miku\"]\n",
        "# @markdown Set `use_preset` for using default prompt, resolution, sampler, and other settings\n",
        "use_presets          = True  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown ### **Launch Arguments**\n",
        "use_gradio_auth      = False  # @param {type: 'boolean'}\n",
        "auto_select_model    = False  # @param {type: 'boolean'}\n",
        "auto_select_vae      = True  # @param {type: 'boolean'}\n",
        "additional_arguments = \"--lowram --theme dark --no-half-vae --opt-sdp-attention\"  # @param {type: 'string'}\n",
        "\n",
        "\n",
        "\n",
        "################################\n",
        "# GLOBAL VARIABLES GOES HERE\n",
        "################################\n",
        "\n",
        "# ───────────── 3) Requirements personalizados (lista tuya) ───\n",
        "MY_REQS = textwrap.dedent(\"\"\"\n",
        "GitPython==3.1.32\n",
        "accelerate\n",
        "blendmodes==2022\n",
        "clean-fid==0.1.35\n",
        "diskcache==5.6.3\n",
        "einops\n",
        "facexlib==0.3.0\n",
        "fastapi==0.104.1\n",
        "gradio==4.40.0\n",
        "httpcore==0.15\n",
        "inflection==0.5.1\n",
        "jsonmerge==1.8.0\n",
        "kornia==0.6.7\n",
        "lark==1.1.2\n",
        "numpy<2                 # ← ### fija NumPy 1.26 para evitar el crash\n",
        "omegaconf==2.2.3\n",
        "open-clip-torch==2.20.0\n",
        "piexif==1.1.3\n",
        "protobuf\n",
        "psutil==5.9.5\n",
        "pytorch_lightning==1.9.4\n",
        "resize-right==0.0.2\n",
        "safetensors\n",
        "scikit-image\n",
        "spandrel==0.3.4\n",
        "spandrel-extra-arches==0.1.1\n",
        "tomesd==0.1.3\n",
        "torch\n",
        "torchdiffeq==0.2.3\n",
        "torchsde==0.2.6\n",
        "transformers==4.46.1\n",
        "httpx==0.24.1\n",
        "pillow-avif-plugin==1.4.3\n",
        "diffusers==0.30.0\n",
        "gradio_rangeslider==0.0.6\n",
        "gradio_imageslider==0.0.20\n",
        "loadimg==0.1.2\n",
        "tqdm==4.66.1\n",
        "onnxruntime\n",
        "onnxruntime-gpu\n",
        "peft==0.13.2\n",
        "pydantic==2.8.2\n",
        "huggingface-hub==0.26.2\n",
        "Pillow\n",
        "setuptools==69.5.1\n",
        "\"\"\").strip()\n",
        "\n",
        "# guardamos requirements → /tmp\n",
        "Path(\"/tmp/reqs.txt\").write_text(MY_REQS + \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# GRADIO AUTH\n",
        "user      = \"cagliostro\"\n",
        "password  = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "output_subdir   = [\"txt2img-samples\", \"img2img-samples\", \"extras-samples\", \"txt2img-grids\", \"img2img-grids\"]\n",
        "\n",
        "config_file_path    = repo_dir / \"config.json\"\n",
        "ui_config_file_path = repo_dir / \"ui-config.json\"\n",
        "\n",
        "package_url = [\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-forge.tar.lz4\",\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-forge-deps.tar.lz4\",\n",
        "]\n",
        "\n",
        "custom_dirs = {\n",
        "    \"model\" : CustomDirs(url=custom_model_url, dst=str(ckpt_dir)),\n",
        "    \"vae\"   : CustomDirs(url=custom_vae_url, dst=str(vae_dir)),\n",
        "    \"lora\"  : CustomDirs(url=custom_lora_url, dst=str(lora_dir)),\n",
        "}\n",
        "\n",
        "default_model_urls = {\n",
        "    \"animagine_xl_3_1\"      : \"https://huggingface.co/cagliostrolab/animagine-xl-3.1/resolve/main/animagine-xl-3.1.safetensors\",\n",
        "    \"rae_diffusion_xl_v2\"   : \"https://huggingface.co/Raelina/Rae-Diffusion-XL-V2/resolve/main/RaeDiffusion-XL-v2.safetensors\",\n",
        "    \"kivotos_xl_v2_0\"       : \"https://huggingface.co/yodayo-ai/kivotos-xl-2.0/resolve/main/kivotos-xl-2.0.safetensors\",\n",
        "    \"urangdiffusion_2_0\"    : \"https://huggingface.co/kayfahaarukku/UrangDiffusion-2.0/resolve/main/UrangDiffusion-2.0.safetensors\",\n",
        "}\n",
        "\n",
        "################################\n",
        "# HELPER FUNCTIONS STARTS HERE\n",
        "################################\n",
        "\n",
        "def mount_drive_function(directory):\n",
        "    output_dir = repo_dir / \"outputs\"\n",
        "\n",
        "    if mount_drive:\n",
        "        print_line(80, color=\"green\")\n",
        "        if not directory.exists():\n",
        "            from google.colab import drive\n",
        "            cprint(\"Mounting google drive...\", color=\"green\", reset=False)\n",
        "            drive.mount(str(directory.parent))\n",
        "        output_dir = directory / output_drive_folder\n",
        "        cprint(\"Set default output path to:\", output_dir, color=\"green\")\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    for dir in [ckpt_dir, vae_dir, lora_dir]:\n",
        "        dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def pre_download(dir, urls, desc, overwrite=False):\n",
        "    ffmpy_path = python_path / \"ffmpy-0.3.0.dist-info\"\n",
        "\n",
        "    for url in tqdm(urls, desc=desc):\n",
        "        filename = Path(url).name\n",
        "        aria2_download(dir, filename, url, quiet=True)\n",
        "        if filename == \"webui-forge-deps.tar.lz4\":\n",
        "            package_utils.extract_package(filename, python_path, overwrite=True)\n",
        "        else:\n",
        "            package_utils.extract_package(filename, \"/\", overwrite=overwrite)\n",
        "        os.remove(dir / filename)\n",
        "\n",
        "    subprocess.run([\"rm\", \"-rf\", str(ffmpy_path)])\n",
        "    subprocess.run([\"pip\", \"install\", \"--force-reinstall\", \"ffmpy\", \"-r\", \"/tmp/reqs.txt\"], check=True)\n",
        "\n",
        "def install_dependencies():\n",
        "    ubuntu_deps = [\"aria2\", \"lz4\"]\n",
        "    cprint(\"Installing ubuntu dependencies\", color=\"green\")\n",
        "    subprocess.run([\"apt\", \"install\", \"-y\"] + ubuntu_deps, check=True)\n",
        "\n",
        "def install_webui(repo_dir, desc):\n",
        "    if not repo_dir.exists():\n",
        "        pre_download(root_dir, package_url, desc, overwrite=False)\n",
        "    else:\n",
        "        cprint(\"Stable Diffusion Web UI Forge already installed, skipping...\", color=\"green\")\n",
        "\n",
        "def configure_output_path(config_path, output_dir, output_subdir):\n",
        "    try:\n",
        "        config = config_utils.read_config(str(config_path))\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        config = {}\n",
        "\n",
        "    config_updates = {\n",
        "        f\"outdir_{subdir.split('-')[0]}_{'_'.join(subdir.split('-')[1:])}\": str(output_dir / subdir)\n",
        "        for subdir in output_subdir\n",
        "    }\n",
        "    config.update(config_updates)\n",
        "\n",
        "    config_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    config_utils.write_config(str(config_path), config)\n",
        "\n",
        "    for dir in output_subdir:\n",
        "        (output_dir / dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def prepare_environment():\n",
        "    cprint(\"Preparing environment...\", color=\"green\")\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF']   = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]      = \"3\"\n",
        "    os.environ[\"PYTHONWARNINGS\"]            = \"ignore\"\n",
        "\n",
        "def custom_download(custom_dirs):\n",
        "    filtered_urls = filter_dict_items(default_model_urls)\n",
        "\n",
        "    for key, value in custom_dirs.items():\n",
        "        urls = value.url.split(\",\")\n",
        "        dst = value.dst\n",
        "\n",
        "        if key == \"model\":\n",
        "            urls.extend(filtered_urls)\n",
        "\n",
        "        if urls[0]:\n",
        "            print_line(80, color=\"green\")\n",
        "            cprint(f\" [-] Downloading Custom {key}...\", color=\"flat_yellow\")\n",
        "\n",
        "        for url in urls:\n",
        "            url = url.strip()\n",
        "            if url != \"\":\n",
        "                print_line(80, color=\"green\")\n",
        "                if \"|\" in url:\n",
        "                    url, filename = map(str.strip, url.split(\"|\"))\n",
        "                    if not filename.endswith((\".safetensors\", \".ckpt\", \".pt\", \"pth\")):\n",
        "                        filename = filename + Path(get_filename(url)).suffix\n",
        "                else:\n",
        "                    filename = get_filename(url)\n",
        "\n",
        "                download(url=url, filename=filename, dst=dst, quiet=False)\n",
        "\n",
        "def additional_downloads():\n",
        "  # This cell will access the data from the previous cell\n",
        "  if not download_items:\n",
        "      print(\"The list is empty. Please add items using the UI in the cell above.\")\n",
        "  else:\n",
        "      print(\"The final list of items is:\")\n",
        "      for item in download_items:\n",
        "          print(item)\n",
        "          download(url=item.url, filename=item.name, dst=item.destPath, quiet=False)\n",
        "\n",
        "def filter_dict_items(dict_items):\n",
        "    result_list = []\n",
        "    for key, url in dict_items.items():\n",
        "        if globals().get(key):\n",
        "            result_list.append(url)\n",
        "    return result_list\n",
        "\n",
        "def auto_select_file(target_dir, config_key, file_types):\n",
        "    valid_files = [f for f in os.listdir(target_dir) if f.endswith(file_types)]\n",
        "    if valid_files:\n",
        "        file_path = random.choice(valid_files)\n",
        "\n",
        "        if Path(target_dir).joinpath(file_path).exists():\n",
        "            config = config_utils.read_config(str(config_file_path))\n",
        "            config[config_key] = file_path\n",
        "            config_utils.write_config(str(config_file_path), config)\n",
        "        return file_path\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def ui_config_presets():\n",
        "    preset_prompt = \"masterpiece, best quality, very aesthetic, absurdres\"\n",
        "    preset_negative_prompt = \"nsfw, lowres, (bad), text, error, fewer, extra, missing, worst quality, jpeg artifacts, low quality, watermark, unfinished, displeasing, oldest, early, chromatic aberration, signature, extra digits, artistic error, username, scan, [abstract]\"\n",
        "\n",
        "    return {\n",
        "        \"txt2img/Prompt/value\"              : preset_prompt,\n",
        "        \"txt2img/Negative prompt/value\"     : preset_negative_prompt,\n",
        "        \"img2img/Prompt/value\"              : preset_prompt,\n",
        "        \"img2img/Negative prompt/value\"     : preset_negative_prompt,\n",
        "        \"customscript/sampler.py/txt2img/Sampling method/value\" : \"Euler a\",\n",
        "        \"customscript/sampler.py/txt2img/Sampling steps/value\"  : 28,\n",
        "        \"customscript/sampler.py/txt2img/Scheduler/value\"       : \"Automatic\",\n",
        "    }\n",
        "\n",
        "def ui_config_settings(ui_config_file: str):\n",
        "    config = config_utils.read_config(str(ui_config_file))\n",
        "    preset_config = ui_config_presets()\n",
        "\n",
        "    for key, value in preset_config.items():\n",
        "        config[key] = value\n",
        "\n",
        "    config_utils.write_config(str(ui_config_file), config)\n",
        "\n",
        "def general_config_presets(config_file: str, lora_dir: str, use_presets: bool, ui_config_file: str):\n",
        "    config = config_utils.read_config(str(config_file))\n",
        "\n",
        "    config.update({\n",
        "        \"CLIP_stop_at_last_layers\"      : 2,\n",
        "        \"show_progress_every_n_steps\"   : 10,\n",
        "        \"show_progressbar\"              : True,\n",
        "        \"samples_filename_pattern\"      : \"[model_name]_[seed]\",\n",
        "        \"show_progress_type\"            : \"Approx NN\",\n",
        "        \"live_preview_content\"          : \"Prompt\",\n",
        "        \"forge_preset\"                  : \"xl\",\n",
        "        \"xl_t2i_width\"                  : 832,\n",
        "        \"xl_t2i_height\"                 : 1216,\n",
        "        \"xl_t2i_cfg\"                    : 7,\n",
        "        \"xl_t2i_hr_cfg\"                 : 7,\n",
        "        \"xl_t2i_sampler\"                : \"Euler a\",\n",
        "        \"xl_t2i_scheduler\"              : \"Automatic\",\n",
        "        \"gradio_theme\"                  : gradio_theme,\n",
        "    })\n",
        "\n",
        "    config_utils.write_config(str(config_file), config)\n",
        "\n",
        "    if use_presets:\n",
        "        ui_config_settings(ui_config_file)\n",
        "\n",
        "def is_valid(target_dir, file_types):\n",
        "    return any(f.endswith(file_types) for f in os.listdir(target_dir))\n",
        "\n",
        "def parse_args(config):\n",
        "    args = []\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args.append(f'\"{v}\"')\n",
        "        elif isinstance(v, str):\n",
        "            args.append(f'--{k}=\"{v}\"')\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args.append(f\"--{k}\")\n",
        "        elif isinstance(v, (float, int)) and not isinstance(v, bool):\n",
        "            args.append(f\"--{k}={v}\")\n",
        "    return \" \".join(args)\n",
        "\n",
        "def main():\n",
        "    global output_dir, auto_select_model, auto_select_vae\n",
        "\n",
        "    ################################\n",
        "    # MAIN EXECUTION\n",
        "    ################################\n",
        "\n",
        "    os.chdir(root_dir)\n",
        "    start_time = time.time()\n",
        "    output_dir = mount_drive_function(drive_dir)\n",
        "\n",
        "    gpu_info    = py_utils.get_gpu_info(get_gpu_name=True)\n",
        "    python_info = py_utils.get_python_version()\n",
        "    torch_info  = py_utils.get_torch_version()\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\" [-] Current GPU: {gpu_info}\", color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Python {python_info}\", color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Torch {torch_info}\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    try:\n",
        "        install_dependencies()\n",
        "\n",
        "        print_line(80, color=\"green\")\n",
        "        install_webui(repo_dir, cprint(\"Unpacking Web UI Forge\", color=\"green\", tqdm_desc=True))\n",
        "        prepare_environment()\n",
        "\n",
        "        configure_output_path(config_file_path, output_dir, output_subdir)\n",
        "\n",
        "        print_line(80, color=\"green\")\n",
        "        if update_webui and not commit_hash:\n",
        "            update_repo(cwd=repo_dir, args=\"-X theirs --rebase --autostash\")\n",
        "        elif commit_hash:\n",
        "            reset_repo(repo_dir, commit_hash)\n",
        "\n",
        "        setup_directories()\n",
        "\n",
        "        repo_name, current_commit_hash, current_branch = validate_repo(repo_dir)\n",
        "        cprint(f\"Using '{repo_name}' repository...\", color=\"green\")\n",
        "        cprint(f\"Branch: {current_branch}, Commit hash: {current_commit_hash}\", color=\"green\")\n",
        "\n",
        "        if update_extensions:\n",
        "            print_line(80, color=\"green\")\n",
        "            batch_update(fetch=True, directory=extensions_dir, desc=cprint(\"Updating extensions\", color=\"green\", tqdm_desc=True))\n",
        "\n",
        "        elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "        print_line(80, color=\"green\")\n",
        "        cprint(f\"Finished installation. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    except Exception as e:\n",
        "        cprint(f\"An error occurred: {str(e)}\", color=\"red\")\n",
        "        print_line(80, color=\"red\")\n",
        "        cprint(\"Setup failed. Please check the error message above and try again.\", color=\"red\")\n",
        "        print_line(80, color=\"red\")\n",
        "        return\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    custom_download(custom_dirs)\n",
        "    additional_downloads()\n",
        "\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Download finished. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Launching '{repo_name}'\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    if not is_valid(ckpt_dir, ('.ckpt', '.safetensors')):\n",
        "        cprint(f\"No checkpoints were found in the directory '{ckpt_dir}'.\", color=\"yellow\")\n",
        "        url = \"https://huggingface.co/cagliostrolab/animagine-xl-3.1/blob/main/animagine-xl-3.1.safetensors\"\n",
        "        filename = get_filename(url)\n",
        "        aria2_download(url=url, download_dir=ckpt_dir, filename=filename)\n",
        "        print_line(80, color=\"green\")\n",
        "        auto_select_model = True\n",
        "\n",
        "    if not is_valid(vae_dir, ('.vae.pt', '.vae.safetensors', '.pt', '.ckpt')):\n",
        "        cprint(f\"No VAEs were found in the directory '{vae_dir}'.\", color=\"yellow\")\n",
        "        url = \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/blob/main/sdxl.vae.safetensors\"\n",
        "        filename = get_filename(url)\n",
        "        aria2_download(url=url, download_dir=vae_dir, filename=filename)\n",
        "        print_line(80, color=\"green\")\n",
        "        auto_select_vae = True\n",
        "\n",
        "    if auto_select_model:\n",
        "        selected_model  = auto_select_file(ckpt_dir, \"sd_model_checkpoint\", ('.ckpt', '.safetensors'))\n",
        "        cprint(f\"Selected Model: {selected_model}\", color=\"green\")\n",
        "\n",
        "    if auto_select_vae:\n",
        "        selected_vae    = auto_select_file(vae_dir, \"sd_vae\", ('.vae.pt', '.vae.safetensors', '.pt', '.ckpt'))\n",
        "        cprint(f\"Selected VAE: {selected_vae}\", color=\"green\")\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    general_config_presets(config_file_path, lora_dir, use_presets, ui_config_file_path)\n",
        "\n",
        "    if use_gradio_auth:\n",
        "      cprint(\"Gradio Auth (use this account to login):\", color=\"green\")\n",
        "      cprint(\"[-] Username: cagliostro\", color=\"green\")\n",
        "      cprint(\"[-] Password:\", password, color=\"green\")\n",
        "      print_line(80, color=\"green\")\n",
        "\n",
        "    config = {\n",
        "        \"enable-insecure-extension-access\": True,\n",
        "        \"disable-safe-unpickle\"           : True,\n",
        "        \"share\"                           : True if not ngrok_token else False,\n",
        "        \"ngrok\"                           : ngrok_token if ngrok_token else None,\n",
        "        \"ngrok-region\"                    : ngrok_region if ngrok_token else None,\n",
        "        \"gradio-auth\"                     : f\"{user}:{password}\" if use_gradio_auth else None,\n",
        "        \"no-hashing\"                      : True,\n",
        "        \"disable-console-progressbars\"    : True,\n",
        "        \"lowram\"                          : True,\n",
        "        \"opt-sub-quad-attention\"          : True,\n",
        "        \"opt-channelslast\"                : True,\n",
        "        \"no-download-sd-model\"            : True,\n",
        "        \"gradio-queue\"                    : True,\n",
        "        \"listen\"                          : True,\n",
        "        \"ckpt-dir\"                        : ckpt_dir,\n",
        "        \"vae-dir\"                         : vae_dir,\n",
        "        \"lora-dir\"                        : lora_dir,\n",
        "    }\n",
        "\n",
        "    args = parse_args(config)\n",
        "    final_args = f\"python launch.py {args} {additional_arguments}\"\n",
        "\n",
        "    cprint()\n",
        "    os.chdir(repo_dir)\n",
        "    ! {final_args}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "YYzHDlgEkkrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a75a71b-f332-489b-fc44-9174f5beb83b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Current GPU: Tesla T4\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Torch 2.6.0+cu124\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mInstalling ubuntu dependencies\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStable Diffusion Web UI Forge already installed, skipping...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mPreparing environment...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mUsing 'lllyasviel/stable-diffusion-webui-forge' repository...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mBranch: main, Commit hash: 862c7a589e43935fa9271bb05399ca003420cbf9\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mFinished installation. Took 2 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'animagine-xl-3.1.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'animagine-xl-3.1.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Downloading Custom vae...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'sdxl_vae.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'sdxl_vae.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "The final list of items is:\n",
            "url='https://civitai.com/api/download/models/290640?type=Model&format=SafeTensor&size=pruned&fp=fp16' name='ponyDiffusionV6XL_v6StartWithThisOne.safetensors' destPath='/content/stable-diffusion-webui-forge/models/Stable-diffusion'\n",
            "\u001b[0m\u001b[0;32mStarting download of 'ponyDiffusionV6XL_v6StartWithThisOne.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'ponyDiffusionV6XL_v6StartWithThisOne.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "url='https://civitai.com/api/download/models/412844?type=Model&format=SafeTensor' name='LeagueOfLegendsPony.safetensors' destPath='/content/stable-diffusion-webui-forge/models/Lora'\n",
            "\u001b[0m\u001b[0;32mStarting download of 'LeagueOfLegendsPony.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'LeagueOfLegendsPony.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "url='https://civitai.com/api/download/models/290640?type=VAE&format=SafeTensor' name='sdxl_vae.safetensors' destPath='/content/stable-diffusion-webui-forge/models/VAE'\n",
            "\u001b[0m\u001b[0;32mStarting download of 'sdxl_vae.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'sdxl_vae.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mDownload finished. Took 1 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mLaunching 'lllyasviel/stable-diffusion-webui-forge'\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mSelected VAE: sdxl.vae.safetensors\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0m\u001b[0m\n",
            "Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Version: f2.0.1v1.10.1-previous-563-g862c7a58\n",
            "Commit hash: 862c7a589e43935fa9271bb05399ca003420cbf9\n",
            "Legacy Preprocessor init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.\n",
            "Launching Web UI with arguments: --enable-insecure-extension-access --disable-safe-unpickle --ngrok=31K1MAUQixUUOkkds39k2sszYxJ_mgMidZTnzeVHnDSa6Nma --ngrok-region=jp --no-hashing --disable-console-progressbars --lowram --opt-sub-quad-attention --opt-channelslast --no-download-sd-model --gradio-queue --listen --lowram --theme dark --no-half-vae --opt-sdp-attention\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu128\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype preferences: [torch.float32] -> torch.float32\n",
            "CUDA Using Stream: False\n",
            "WARNING:bitsandbytes.cextension:Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.11/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
            "WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755447238.789681   11626 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755447238.797601   11626 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755447238.819673   11626 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755447238.819701   11626 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755447238.819707   11626 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755447238.819711   11626 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Using pytorch cross attention\n",
            "Using pytorch attention for VAE\n",
            "ngrok authtoken detected, trying to connect...\n",
            "ngrok connected to localhost:7860! URL: https://f24da4af30a2.ngrok-free.app\n",
            "You can use this link after the launch is complete.\n",
            "ControlNet preprocessor location: /content/stable-diffusion-webui-forge/models/ControlNetPreprocessor\n",
            "Tag Autocomplete: Could not locate model-keyword extension, Lora trigger word completion will be limited to those added through the extra networks menu.\n",
            "\u001b[38;5;208m▶\u001b[0m SD-Hub: \u001b[38;5;39mv4.9.1\u001b[0m\n",
            "[Vec. CC] Style Sheet Loaded...\n",
            "Loading additional modules ... done.\n",
            "2025-08-17 16:14:17,287 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
            "Model selected: {'checkpoint_info': {'filename': '/content/stable-diffusion-webui-forge/models/Stable-diffusion/animagine-xl-3.1.safetensors', 'hash': 'c798d390'}, 'additional_modules': [], 'unet_storage_dtype': None}\n",
            "Using online LoRAs in FP16: False\n",
            "Running on local URL:  http://0.0.0.0:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n",
            "\u001b[92mIIB Database file has been successfully backed up to the backup folder.\u001b[0m\n",
            "Startup time: 35.0s (prepare environment: 7.0s, import torch: 12.9s, other imports: 0.5s, load scripts: 3.1s, initialize google blockly: 5.9s, create ui: 2.9s, gradio launch: 2.1s, app_started_callback: 0.4s).\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 1024.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 93.22% GPU memory (14071.00 MB) to load weights, and use 6.78% GPU memory (1024.00 MB) to do matrix computation.\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 1017.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 93.26% GPU memory (14078.00 MB) to load weights, and use 6.74% GPU memory (1017.00 MB) to do matrix computation.\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 1024.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 93.22% GPU memory (14071.00 MB) to load weights, and use 6.78% GPU memory (1024.00 MB) to do matrix computation.\n",
            "Model selected: {'checkpoint_info': {'filename': '/content/stable-diffusion-webui-forge/models/Stable-diffusion/ponyDiffusionV6XL_v6StartWithThisOne.safetensors', 'hash': 'e577480d'}, 'additional_modules': [], 'unet_storage_dtype': None}\n",
            "Using online LoRAs in FP16: False\n",
            "Loading Model: {'checkpoint_info': {'filename': '/content/stable-diffusion-webui-forge/models/Stable-diffusion/ponyDiffusionV6XL_v6StartWithThisOne.safetensors', 'hash': 'e577480d'}, 'additional_modules': [], 'unet_storage_dtype': None}\n",
            "[Unload] Trying to free all memory for cuda:0 with 0 models keep loaded ... Done.\n",
            "StateDict Keys: {'unet': 1680, 'vae': 248, 'text_encoder': 197, 'text_encoder_2': 518, 'ignore': 0}\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "K-Model Created: {'storage_dtype': torch.float16, 'computation_dtype': torch.float16}\n",
            "Model loaded in 27.2s (unload existing model: 0.6s, forge model load: 26.6s).\n",
            "Downloading VAEApprox model to: /content/stable-diffusion-webui-forge/models/VAE-approx/vaeapprox-sdxl.pt\n",
            "100% 209k/209k [00:00<00:00, 12.2MB/s]\n",
            "[LORA] Loaded /content/stable-diffusion-webui-forge/models/Lora/LeagueOfLegendsPony.safetensors for KModel-UNet with 722 keys at weight 1.0 (skipped 0 keys) with on_the_fly = False\n",
            "[Unload] Trying to free 3051.58 MB for cuda:0 with 0 models keep loaded ... Done.\n",
            "[Memory Management] Target: JointTextEncoder, Free GPU: 9972.72 MB, Model Require: 1559.68 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 7389.05 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 6.49 seconds\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 8173.20 MB ... Done.\n",
            "[Unload] Trying to free 2856.18 MB for cuda:0 with 0 models keep loaded ... Current free memory is 8171.69 MB ... Done.\n",
            "[Memory Management] Target: KModel, Free GPU: 8171.69 MB, Model Require: 0.00 MB, Previously Loaded: 4897.05 MB, Inference Require: 1024.00 MB, Remaining: 7147.69 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 6.12 seconds\n",
            "100% 40/40 [00:34<00:00,  1.17it/s]\n",
            "[Unload] Trying to free 8820.57 MB for cuda:0 with 0 models keep loaded ... Current free memory is 8155.35 MB ... Unload model JointTextEncoder Current free memory is 9919.54 MB ... Done.\n",
            "[Memory Management] Target: IntegratedAutoencoderKL, Free GPU: 9919.54 MB, Model Require: 319.11 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 8576.42 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 2.18 seconds\n",
            "[Unload] Trying to free 3302.87 MB for cuda:0 with 0 models keep loaded ... Current free memory is 9599.04 MB ... Done.\n",
            "[Memory Management] Target: JointTextEncoder, Free GPU: 9599.04 MB, Model Require: 1752.98 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 6822.06 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 0.54 seconds\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7838.69 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7837.19 MB ... Done.\n",
            "100% 40/40 [00:35<00:00,  1.13it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7825.61 MB ... Unload model JointTextEncoder Current free memory is 9585.34 MB ... Done.\n",
            "Memory cleanup has taken 0.77 seconds\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9585.34 MB ... Done.\n",
            "100% 40/40 [00:33<00:00,  1.18it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9573.77 MB ... Done.\n",
            "[Unload] Trying to free 3302.87 MB for cuda:0 with 0 models keep loaded ... Current free memory is 9574.01 MB ... Done.\n",
            "[Memory Management] Target: JointTextEncoder, Free GPU: 9574.01 MB, Model Require: 1752.98 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 6797.03 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 0.56 seconds\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7812.91 MB ... Done.\n",
            "[Unload] Trying to free 2529.28 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7811.17 MB ... Done.\n",
            "100% 40/40 [01:10<00:00,  1.77s/it]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7799.59 MB ... Unload model JointTextEncoder Current free memory is 9560.07 MB ... Done.\n",
            "Memory cleanup has taken 0.83 seconds\n",
            "[Unload] Trying to free 3302.87 MB for cuda:0 with 0 models keep loaded ... Current free memory is 9560.56 MB ... Done.\n",
            "[Memory Management] Target: JointTextEncoder, Free GPU: 9560.56 MB, Model Require: 1752.98 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 6783.58 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 0.56 seconds\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7798.71 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7797.33 MB ... Done.\n",
            "100% 40/40 [00:17<00:00,  2.32it/s]\n",
            "[Unload] Trying to free 2178.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7791.33 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7791.45 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7790.84 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7789.51 MB ... Done.\n",
            "100% 40/40 [00:09<00:00,  4.39it/s]\n",
            "[Unload] Trying to free 2178.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7786.51 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7786.51 MB ... Done.\n",
            "100% 40/40 [00:09<00:00,  4.26it/s]\n",
            "[Unload] Trying to free 2178.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7783.51 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7786.58 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7785.96 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7784.61 MB ... Done.\n",
            "100% 40/40 [00:14<00:00,  2.81it/s]\n",
            "[Unload] Trying to free 3267.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7780.11 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7780.11 MB ... Done.\n",
            "100% 40/40 [00:14<00:00,  2.82it/s]\n",
            "[Unload] Trying to free 3267.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7780.11 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7780.20 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7779.59 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7778.14 MB ... Done.\n",
            "100% 40/40 [00:26<00:00,  1.52it/s]\n",
            "[Unload] Trying to free 3267.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7769.14 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7769.33 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7768.72 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7767.27 MB ... Done.\n",
            "100% 20/20 [00:12<00:00,  1.60it/s]\n",
            "[Unload] Trying to free 3267.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7758.27 MB ... Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from colablib.sd_models.downloader import aria2_download, download\n",
        "\n",
        "more_url         = \"https://civitai.com/api/download/models/412844?type=Model&format=SafeTensor\"  # @param {type: 'string'}\n",
        "more_name    = \"LeagueOfLegendsPony.safetensors\"  # @param {type: 'string'}\n",
        "more_dest   = \"lora\"  # @param [\"checkpoint\", \"vae\", \"lora\" ]\n",
        "token = \"30e3b04ba4dd599b49369258c7fe2994\" # @param {type: 'string'}\n",
        "if token != '':\n",
        "  more_url = more_url + \"&token=\" + token\n",
        "\n",
        "\n",
        "print(f\" more download Item {more_name}, {more_url}, {true_dest_paths[more_dest]}\")\n",
        "download(url=more_url, dst=true_dest_paths[more_dest], filename=more_name,  quiet=False)\n"
      ],
      "metadata": {
        "id": "8AYune0dtX5x",
        "outputId": "a2921693-9bfc-4459-f7f5-9381fb9e7497",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " more download Item LeagueOfLegendsPony.safetensors, https://civitai.com/api/download/models/412844?type=Model&format=SafeTensor&token=30e3b04ba4dd599b49369258c7fe2994, /content/stable-diffusion-webui-forge/models/Lora\n",
            "\u001b[0m\u001b[0;32mStarting download of 'LeagueOfLegendsPony.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'LeagueOfLegendsPony.safetensors' completed. Took 2 sec.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images**\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from colablib.colored_print import cprint\n",
        "\n",
        "os.chdir(output_dir)\n",
        "\n",
        "use_drive = False  # @param {type:\"boolean\"}\n",
        "folder_name = \"cagliostro-forge-colab\"  # @param {type: \"string\"}\n",
        "filename = \"waifu.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "def get_unique_filename(base_filename):\n",
        "    path = Path(base_filename)\n",
        "    if not path.exists():\n",
        "        return path\n",
        "    i = 1\n",
        "    while True:\n",
        "        new_path = path.with_name(f\"{path.stem}({i}){path.suffix}\")\n",
        "        if not new_path.exists():\n",
        "            return new_path\n",
        "        i += 1\n",
        "\n",
        "filename = get_unique_filename(filename)\n",
        "\n",
        "def zip_directory(directory, zipname):\n",
        "    with zipfile.ZipFile(zipname, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for file_path in directory.rglob('*'):\n",
        "            if file_path.is_file():\n",
        "                zipf.write(file_path, file_path.relative_to(directory.parent))\n",
        "\n",
        "zip_directory(output_dir, Path('/content/outputs.zip'))\n",
        "\n",
        "if use_drive:\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive_service = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        query = f\"title='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "        file_list = drive_service.ListFile({\"q\": query}).GetList()\n",
        "        if file_list:\n",
        "            cprint(\"Debug: Folder exists\", color=\"green\")\n",
        "            return file_list[0][\"id\"]\n",
        "        else:\n",
        "            cprint(\"Debug: Creating folder\", color=\"green\")\n",
        "            folder = drive_service.CreateFile({\n",
        "                \"title\": folder_name,\n",
        "                \"mimeType\": \"application/vnd.google-apps.folder\"\n",
        "            })\n",
        "            folder.Upload()\n",
        "            return folder[\"id\"]\n",
        "\n",
        "    def upload_file(file_path, folder_id, save_as):\n",
        "        save_as = get_unique_filename(save_as)\n",
        "        file = drive_service.CreateFile({\"title\": save_as.name, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(str(file_path))\n",
        "        file.Upload()\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file[\"id\"]\n",
        "\n",
        "    folder_id = create_folder(folder_name)\n",
        "    file_id = upload_file(Path('/content/outputs.zip'), folder_id, Path(save_as))\n",
        "    sharing_link = f\"https://drive.google.com/file/d/{file_id}/view?usp=sharing\"\n",
        "    cprint(f\"Your sharing link: {sharing_link}\", color=\"green\")\n",
        "else:\n",
        "    cprint(\"Files zipped locally. Download manually from the files tab.\", color=\"yellow\")\n"
      ],
      "metadata": {
        "id": "UyTKsCa1qUL4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}